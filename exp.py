import fitz  # PyMuPDF âœ pip install pymupdf
import re
import json
from pathlib import Path
from tkinter import Tk, filedialog
import pdfplumber, re ,camelot



# ---------- ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø£Ø±Ù‚Ø§Ù… Ø§Ù„Ù‡Ù†Ø¯ÙŠØ© Ø¥Ù„Ù‰ Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ© ----------
def convert_arabic_digits(txt: str) -> str:
    arabic = "Ù Ù¡Ù¢Ù£Ù¤Ù¥Ù¦Ù§Ù¨Ù©"
    for i, d in enumerate(arabic):
        txt = txt.replace(d, str(i))
    return txt

# ---------- Ø§Ù„ØªÙ‚Ø§Ø· Ø£ÙˆÙ„ ØªØ·Ø§Ø¨Ù‚ ----------
def _grab(patterns, text, default=None, flags=re.IGNORECASE):
    if isinstance(patterns, str):
        patterns = [patterns]
    for pat in patterns:
        m = re.search(pat, text, flags)
        if m:
            return m.group(1).strip()
    return default

# ---------- Field A ----------
def extract_field_experience_details(text: str) -> dict:
    modes = []
    if re.search(r"[â˜’Xx]\s*In[- ]?person", text, re.IGNORECASE):
        modes.append("In-person")
    if re.search(r"[â˜’Xx]\s*Hybrid", text, re.IGNORECASE):
        modes.append("Hybrid")
    if re.search(r"[â˜’Xx]\s*Online", text, re.IGNORECASE):
        modes.append("Online")

    return {
        "Credit Hours": _grab(r"Credit\s*hours.*?\(\s*(\d+)\s*credit", text),
        "Level/Year": _grab(r"Level\/year.*?offered:\s*(.*?)\n", text),
        "Duration": {
        "Weeks": int(convert_arabic_digits(_grab(r"\(\s*([\dÙ -Ù©]+)\s*\)\s*Weeks", text, "0"))),
        "Days": int(convert_arabic_digits(_grab(r"\(\s*([\dÙ -Ù©]+)\s*\)\s*Days", text, "0"))),
        "Hours": int(convert_arabic_digits(_grab(r"\(\s*([\dÙ -Ù©]+)\s*\)\s*Hours", text, "0"))),
},

        "Corequisite": _grab([
            r"Corequisite.*?\n\s*(.*?)\n",
            r"Corequisite.*?:\s*(.*?)\n"
        ], text, ""),
        "Delivery Mode": modes
    }

# ---------- Field B ----------
def extract_clos_grouped(file_path: str) -> dict:
    import camelot

    tables = camelot.read_pdf(file_path, pages='all', flavor='stream')  # or 'lattice' if borders are clear
    print(f"âœ… Found {len(tables)} tables.")

    # Ù†ÙØªØ±Ø¶ Ø£Ù† Ø§Ù„Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ù…Ù†Ø§Ø³Ø¨ Ù‡Ùˆ Ø±Ù‚Ù… 1 Ø­Ø³Ø¨ Ø§Ø®ØªØ¨Ø§Ø±Ùƒ Ø§Ù„Ø³Ø§Ø¨Ù‚
    table = tables[1].df
    clos = {}
    current_section = None

    for index, row in table.iterrows():
        # ØªØ®Ø·Ù‰ Ø§Ù„ØµÙÙˆÙ Ø§Ù„ÙØ§Ø±ØºØ©
        if row.isnull().all() or row[0].strip() == "":
            continue

        code = row[0].strip()

        # Ø¥Ø°Ø§ Ø§Ù„ØµÙ Ø¹Ø¨Ø§Ø±Ø© Ø¹Ù† Ø¹Ù†ÙˆØ§Ù† Ø±Ø¦ÙŠØ³ÙŠ (Ù…Ø«Ù„ 2.0 Skills)
        if re.match(r"^\d+\.0$", code):
            current_section = code
            clos[current_section] = {
                "Title": row[1].strip(),
                "Items": []
            }
            continue

        # Ø¥Ø°Ø§ Ø§Ù„ØµÙ Ø¹Ø¨Ø§Ø±Ø© Ø¹Ù† CLO Ø¹Ø§Ø¯ÙŠ
        if re.match(r"^\d+\.\d+$", code) and current_section:
            try:
                clos[current_section]["Items"].append({
                    "Code": code,
                    "Outcome": row[1].strip(),
                    "PLO Code": row[2].strip(),
                    "Activities": row[3].strip(),
                    "Assessment Methods": row[4].strip(),
                    "Responsibility": row[5].strip()
                })
            except IndexError:
                print(f"âš ï¸ Skipping incomplete row at index {index}: {row}")

    return clos






# ---------- Field C ----------
def extract_spec_approval_data(text: str) -> dict:
    council = _grab(r"Council\s*/Committee\s*(.*?)\n", text, "")
    reference_no = _grab(r"Reference No\.\s*(\d+)", text, "")
    date = _grab(r"Date\s*([\d/]+\s*H\s*[â€“-]\s*[\dA-Z\s]+)", text, "")

    return {
        "Council/Committee": council,
        "Reference No": reference_no,
        "Date": date
    }



# ---------- Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ----------
def extract_data(file_path):
    doc = fitz.open(file_path)
    text = "\n".join(page.get_text() for page in doc)

    return {
        "General Info": {
            "Course Title"      : _grab(r"Course Title:\s+(.*?)\n", text),
            "Course Code"       : _grab(r"Course Code:\s+(.*?)\n",  text),
            "Program"           : _grab(r"Program:\s+(.*?)\n",      text),
            "Department"        : _grab(r"Department:\s+(.*?)\n",   text),
            "College"           : _grab(r"College:\s+(.*?)\n",      text),
            "Institution"       : _grab(r"Institution:\s+(.*?)\n",  text),
            "Version"           : _grab(r"Field Experience Version Number:\s+(.*?)\n", text),
            "Last Revision Date": _grab(r"Last Revision Date:\s+(.*?)\n",             text),
        },
        "Field Experience Details": extract_field_experience_details(text),
        "Field Experience Course Learning Outcomes (CLOs), Training Activities and Assessment Methods":
        extract_clos_grouped(file_path),

        "Specification Approval Data": extract_spec_approval_data(text)
 

    }

# ---------- ÙˆØ§Ø¬Ù‡Ø© Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù…Ù„Ù ----------
def select_pdf_file():
    root = Tk()
    root.withdraw()  # Ø¥Ø®ÙØ§Ø¡ Ù†Ø§ÙØ°Ø© Tk
    filepath = filedialog.askopenfilename(
        title="Ø§Ø®ØªØ± Ù…Ù„Ù PDF",
        filetypes=[("PDF Files", "*.pdf")]
    )
    return filepath

# ---------- Ù†Ù‚Ø·Ø© Ø§Ù„Ø¨Ø¯Ø§ÙŠØ© ----------
if __name__ == "__main__":
    pdf_path = select_pdf_file()

    if not pdf_path:
        print("âŒ Ù„Ù… ÙŠØªÙ… Ø§Ø®ØªÙŠØ§Ø± Ø£ÙŠ Ù…Ù„Ù.")
        exit()

    print(f"âœ… Ø¬Ø§Ø±ÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ù„Ù: {pdf_path}")
    data = extract_data(pdf_path)

    # Ø·Ø¨Ø§Ø¹Ø© Ø§Ù„Ù†ØªØ§Ø¦Ø¬
    print("\nğŸ“‹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬Ø©:")
    for section, fields in data.items():
        print(f"\nğŸ”¹ {section}")
        for k, v in fields.items():
            print(f"{k:<25}: {v}")

    # Ø­ÙØ¸ JSON
    json_path = Path(__file__).parent / (Path(pdf_path).stem + ".json")
    with open(json_path, "w", encoding="utf-8") as f:
        json.dump(data, f, indent=4, ensure_ascii=False)

    print(f"\nâœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙÙŠ: {json_path}")
